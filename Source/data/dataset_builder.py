import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from data_fetcher import load_multitimeframe_data
from labeling_utils import (
    label_binary, label_three_class,
    label_position_class, label_return_regression
)
from _data_config import (
    SYMBOL_LIST, TARGET_INTERVAL, TARGET_COLUMN,
    INTERVAL_MINUTES, REQUIRED_LENGTH, LABEL_THRESHOLDS
)

def get_threshold(interval):
    return LABEL_THRESHOLDS.get(interval, 0.01)

def normalize_features(X):
    scaler = MinMaxScaler()
    X = np.nan_to_num(X, nan=0.0, posinf=1e10, neginf=-1e10)
    X = X.reshape(-1, X.shape[2])
    X = scaler.fit_transform(X)
    X = X.reshape(-1, X.shape[1], X.shape[2])
    return X, scaler

def build_lstm_dataset(symbol):
    mtf_data = load_multitimeframe_data(symbol)
    if not mtf_data["stock"] or not mtf_data["index"]:
        print(f"‚ùå {symbol}: Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ïã§Ìå® (stock or index)")
        return None, None

    if TARGET_INTERVAL not in mtf_data["stock"]:
        print(f"‚ùå {symbol}: {TARGET_INTERVAL} Î∂ÑÎ¥â Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
        return None, None

    target_df = mtf_data["stock"][TARGET_INTERVAL]
    threshold = get_threshold(TARGET_INTERVAL)

    features, labels = [], []
    ref_shape = None

    for i in range(REQUIRED_LENGTH[TARGET_INTERVAL], len(target_df) - 1):
        anchor_time = target_df.index[i]
        stack, valid = [], True

        for interval in INTERVAL_MINUTES.keys():
            win_len = REQUIRED_LENGTH[interval]
            for key in ["stock", "index"]:
                df = mtf_data[key].get(interval)
                if df is None or len(df) < win_len:
                    valid = False
                    break

                pos = df.index.get_indexer([anchor_time], method="nearest")[0]
                if pos == -1 or pos < win_len:
                    valid = False
                    break
                df_slice = df.iloc[pos - win_len + 1 : pos + 1]
                if len(df_slice) < win_len:
                    valid = False
                    break
                stack.append(df_slice.values)
            if not valid:
                break

        if not valid or len(stack) != len(INTERVAL_MINUTES) * 2:
            continue

        x = np.concatenate(stack, axis=1)
        if ref_shape is None:
            ref_shape = x.shape[1]
        if x.shape[1] != ref_shape:
            continue

        features.append(x)
        label_df = target_df.iloc[i:i+2]
        try:
            label_dict = {
                "binary": label_binary(label_df, threshold=threshold).iloc[0],
                "three": label_three_class(label_df, threshold=threshold).iloc[0],
                "position": label_position_class(label_df, threshold=threshold).iloc[0],
                "regression": label_return_regression(label_df, threshold=threshold).iloc[0]
            }
            labels.append(label_dict)
        except Exception as e:
            print(f"‚ùå ÎùºÎ≤® ÏÉùÏÑ± Ïã§Ìå®: {e}")
            continue

    X = np.stack(features, axis=0) if features else None
    y = labels if labels else None
    return X, y

def build_generic_dataset(interval: str):
    global TARGET_INTERVAL
    TARGET_INTERVAL = interval

    X_all, y_all = [], []
    expected_dim = None

    for symbol in SYMBOL_LIST:
        print(f"üì° [{symbol} / {interval}] Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉùÏÑ± Ï§ë...")
        X, y = build_lstm_dataset(symbol)

        if X is None or y is None:
            continue
        if expected_dim is None:
            expected_dim = X.shape[2]
        if X.shape[2] != expected_dim:
            print(f"‚ö†Ô∏è {symbol}: Ï∞®Ïõê Î∂àÏùºÏπò ‚Üí Í±¥ÎÑàÎúÄ")
            continue

        X_all.append(X)
        y_all.extend(y)  # Î¶¨Ïä§Ìä∏ÎãàÍπå Í∑∏ÎÉ• extend

    if not X_all:
        print(f"‚ùå {interval} Í∏∞Ï§Ä ÌïôÏäµ Í∞ÄÎä•Ìïú Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå")
        return None, None

    X = np.concatenate(X_all, axis=0)
    y = y_all
    print(f"‚úÖ {interval} Í∏∞Ï§Ä Ï¥ù ÏÉòÌîå Ïàò: {X.shape[0]}")
    return X, y
